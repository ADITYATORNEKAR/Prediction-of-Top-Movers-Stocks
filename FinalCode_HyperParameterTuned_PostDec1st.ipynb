{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7UdcCemKDWS",
    "outputId": "6c6facae-f02d-4cb7-ba6f-cbf3cbde7e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.23.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.1.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->pandas-datareader) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->pandas-datareader) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
      "Collecting get-all-tickers\n",
      "  Downloading https://files.pythonhosted.org/packages/26/a3/d6469bd207bf73b769b94f6000be4ea83cad26a6a32a5fea726cd2522e7e/get_all_tickers-1.7.tar.gz\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from get-all-tickers) (1.1.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from get-all-tickers) (2.23.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->get-all-tickers) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->get-all-tickers) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->get-all-tickers) (1.18.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->get-all-tickers) (1.15.0)\n",
      "Building wheels for collected packages: get-all-tickers\n",
      "  Building wheel for get-all-tickers (setup.py): started\n",
      "  Building wheel for get-all-tickers (setup.py): finished with status 'done'\n",
      "  Created wheel for get-all-tickers: filename=get_all_tickers-1.7-cp36-none-any.whl size=4242 sha256=e6d9ec757850b96a503fc0da18f4fa8369cc61425ae15cf6ba78c5be17df86da\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/8b/ef/6cd3580f4b479aef881a32bd937c282982e3d186b617a663ac\n",
      "Successfully built get-all-tickers\n",
      "Installing collected packages: get-all-tickers\n",
      "Successfully installed get-all-tickers-1.7\n",
      "Collecting yfinance\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.1.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
      "Collecting lxml>=4.5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/78/56a7c88a57d0d14945472535d0df9fb4bbad7d34ede658ec7961635c790e/lxml-4.6.2-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.11.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Building wheels for collected packages: yfinance\n",
      "  Building wheel for yfinance (setup.py): started\n",
      "  Building wheel for yfinance (setup.py): finished with status 'done'\n",
      "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22618 sha256=a0d7cd07d35bc3a86679e635898596cb7d8db505ad23790e9bbbfa35e96e78ca\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
      "Successfully built yfinance\n",
      "Installing collected packages: lxml, yfinance\n",
      "  Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "Successfully installed lxml-4.6.2 yfinance-0.1.55\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pandas-datareader\n",
    "pip install get-all-tickers\n",
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9iAj3zUpKEMm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "from collections import Iterable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame\n",
    "from get_all_tickers import get_tickers as gt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#getting the labels\n",
    "news_data = pd.read_csv('Combined_News_DJIA.csv', index_col=0)\n",
    "labels = news_data[['Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klxsSC4jmj5j"
   },
   "source": [
    "# USER INPUT REQUIRED FOR STOCK SELECTION, DATE & DECIDING TOP MOVER THRESHOLD PERCENTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNDLFqF-ofl7",
    "outputId": "57f362f4-1ff8-4e05-8eff-3429020a4bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which stocks do you want to check: SOHU,NKTR\n",
      "Please enter date between 2008/08/08 and 2016/07/01 in yyyy-mm-dd format to use Market Sentiment:2016-06-30\n",
      "Please enter % threshold to define top movers stocks:20\n"
     ]
    }
   ],
   "source": [
    "stocks = input(\"Which stocks do you want to check: \")\n",
    "#ZION,KGC,AMD,SOHU,BLIN,WMT,AMGN,NKTR,T,AAPL   <-------using this as first input for test purposes(any ticker stoc symbols could be used)\n",
    "date_check = input(\"Please enter date between 2008/08/08 and 2016/07/01 in yyyy-mm-dd format to use Market Sentiment:\")\n",
    "#2016-06-30        <----------- use this as second input\n",
    "defined_topmover_threshold = input(\"Please enter % threshold to define top movers stocks:\")  ## Set this to define top mover threshold percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9o16X_RPt8wU"
   },
   "outputs": [],
   "source": [
    "def Convert(string): \n",
    "    li = list(string.split(\",\")) \n",
    "    return li\n",
    "stocks=Convert(stocks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fgUDP4Dhszh6",
    "outputId": "55d02ec0-e90a-4095-ec27-ef29e0ef97f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOHU\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NKTR\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "import pandas as pd\n",
    "\n",
    "# Tickers list\n",
    "# We can add and delete any ticker from the list to get desired ticker live data\n",
    "ticker_list=stocks\n",
    "# We can get data by our choice by giving days bracket\n",
    "start_date= '2008-08-08'\n",
    "end_date=date_check\n",
    "files=[]\n",
    "# Create a data folder in your current dir.\n",
    "def SaveData(df, filename):\n",
    "  df.to_csv('./'+filename+'.csv')\n",
    "def getData(ticker):\n",
    "  print (ticker)\n",
    "  data = pdr.get_data_yahoo(ticker, start=start_date, end=end_date)\n",
    "  dataname = ticker\n",
    "  files.append(dataname)\n",
    "  SaveData(data, dataname)\n",
    "\n",
    "#This loop will iterate over ticker list, will pass one ticker to get data, and save that data as file.\n",
    "for tik in ticker_list:\n",
    "  getData(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZjHOiSt9KYV-"
   },
   "outputs": [],
   "source": [
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Aq1QH8xwKaUT"
   },
   "outputs": [],
   "source": [
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyAks7m3mNsm"
   },
   "source": [
    "# LSTM PREDICTIONS WITHOUT SENTIMENT SCORE INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef8VzxR-jSNq",
    "outputId": "e6011753-ec0b-4a37-b14e-e638389871c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################################\n",
      "MSE for ZION stock excluding Sentiment scores information: 0.5847963690757751\n",
      "Predicted stock price inverse transformed: [16.983372]\n",
      "Previous day data: Open         2.412000e+01\n",
      "High         2.450000e+01\n",
      "Low          2.386000e+01\n",
      "Close        2.439000e+01\n",
      "Adj Close    2.208469e+01\n",
      "Volume       4.786600e+06\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-23.098904]\n",
      "ZION stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for KGC stock excluding Sentiment scores information: 0.7469857931137085\n",
      "Predicted stock price inverse transformed: [13.109369]\n",
      "Previous day data: Open         5.020000e+00\n",
      "High         5.110000e+00\n",
      "Low          4.950000e+00\n",
      "Close        4.960000e+00\n",
      "Adj Close    4.922116e+00\n",
      "Volume       1.558420e+07\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [166.33603]\n",
      "KGC stock is predicted to be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for AMD stock excluding Sentiment scores information: 1.298218011856079\n",
      "Predicted stock price inverse transformed: [3.8001509]\n",
      "Previous day data: Open                4.95\n",
      "High                5.19\n",
      "Low                 4.91\n",
      "Close               5.12\n",
      "Adj Close           5.12\n",
      "Volume       29221400.00\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-25.778303]\n",
      "AMD stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for SOHU stock excluding Sentiment scores information: 0.5411022305488586\n",
      "Predicted stock price inverse transformed: [50.08815]\n",
      "Previous day data: Open             36.430000\n",
      "High             36.980000\n",
      "Low              36.130001\n",
      "Close            36.590000\n",
      "Adj Close        36.590000\n",
      "Volume       149100.000000\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [36.89027]\n",
      "SOHU stock is predicted to be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for BLIN stock excluding Sentiment scores information: 0.038675256073474884\n",
      "Predicted stock price inverse transformed: [1296.5532]\n",
      "Previous day data: Open          265.0\n",
      "High          300.0\n",
      "Low           262.5\n",
      "Close         287.5\n",
      "Adj Close     287.5\n",
      "Volume       2500.0\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [350.97504]\n",
      "BLIN stock is predicted to be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for WMT stock excluding Sentiment scores information: 0.3214268684387207\n",
      "Predicted stock price inverse transformed: [44.883896]\n",
      "Previous day data: Open         7.176000e+01\n",
      "High         7.187000e+01\n",
      "Low          7.067000e+01\n",
      "Close        7.151000e+01\n",
      "Adj Close    6.463261e+01\n",
      "Volume       8.561200e+06\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-30.555338]\n",
      "WMT stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for AMGN stock excluding Sentiment scores information: 1.0065758228302002\n",
      "Predicted stock price inverse transformed: [56.257065]\n",
      "Previous day data: Open         1.458900e+02\n",
      "High         1.484200e+02\n",
      "Low          1.456000e+02\n",
      "Close        1.484200e+02\n",
      "Adj Close    1.308070e+02\n",
      "Volume       4.348000e+06\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-56.992306]\n",
      "AMGN stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for NKTR stock excluding Sentiment scores information: 1.4255315065383911\n",
      "Predicted stock price inverse transformed: [10.452128]\n",
      "Previous day data: Open              13.58\n",
      "High              13.93\n",
      "Low               13.54\n",
      "Close             13.76\n",
      "Adj Close         13.76\n",
      "Volume       1069700.00\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-24.039766]\n",
      "NKTR stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for T stock excluding Sentiment scores information: 0.9825729131698608\n",
      "Predicted stock price inverse transformed: [19.266132]\n",
      "Previous day data: Open         4.214000e+01\n",
      "High         4.217000e+01\n",
      "Low          4.187000e+01\n",
      "Close        4.202000e+01\n",
      "Adj Close    3.250517e+01\n",
      "Volume       3.441900e+07\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-40.72902]\n",
      "T stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "##############################################################################\n",
      "MSE for AAPL stock excluding Sentiment scores information: 0.5326589345932007\n",
      "Predicted stock price inverse transformed: [8.377337]\n",
      "Previous day data: Open         2.322500e+01\n",
      "High         2.341500e+01\n",
      "Low          2.303500e+01\n",
      "Close        2.339750e+01\n",
      "Adj Close    2.174936e+01\n",
      "Volume       1.617796e+08\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-61.482376]\n",
      "AAPL stock might not be a top mover the next day\n",
      "##############################################################################\n"
     ]
    }
   ],
   "source": [
    "##ZION,KGC,AMD,SOHU,BLIN,WMT,AMGN,NKTR,T,AAPL\n",
    "\n",
    "for tik in ticker_list:\n",
    "  tik_data=pd.read_csv(tik+'.csv',index_col=0)\n",
    "  temp_data=tik_data.drop(['Close'],axis=1)\n",
    "  \n",
    "  with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "  #Scaling the variables(x) and variable(y)\n",
    "  sca = temp_data.iloc[:,:]\n",
    "  #Standardization of data is required as the dataset consists of variables of different scales\n",
    "  sc = StandardScaler()\n",
    "  ysc = StandardScaler()\n",
    "  scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "  scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "  \n",
    "  #Y scaling for later inverse transforming predictions\n",
    "  yscalesenti = with_sentiment_data\n",
    "  y_with_sentiscal = ysc.fit_transform(yscalesenti.iloc[:,4].to_numpy().reshape(-1,1))\n",
    "  with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "\n",
    "  with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "  x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "  y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "  \n",
    "  x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "  y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "  #Splitting data into training(70% data) and testing data(30% data)\n",
    "  #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "  \n",
    "  x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "  x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "  TIME_STEPS = 1\n",
    "\n",
    "  #creating lags for with sentiment scores\n",
    "  \n",
    "  x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "  x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "  \n",
    "  #creating lags for without sentiment scores\n",
    "  \n",
    "  x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "  x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "  \n",
    "  x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "  x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "  \n",
    "  x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "  x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "  \n",
    "  np.random.seed = 1   \n",
    "  tf.random.set_seed = 2  \n",
    "  time3=fun_t()\n",
    "  history=History()\n",
    "  lstm_model = Sequential()\n",
    "  lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "  lstm_model.add(keras.layers.Dense(units = 1))\n",
    "  lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "  history = lstm_model.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "  time_lstm = list(time3.times)\n",
    "  train_lstm = history.history.get('loss')\n",
    "  val_lstm = history.history.get('val_loss')\n",
    "  mse=val_lstm[-1]\n",
    "  print(\"##############################################################################\")\n",
    "  print('MSE for',tik,'stock excluding Sentiment scores information:',mse)\n",
    "  predicted_stock_price=lstm_model.predict(x_test_without_sentiment_scores)\n",
    "  predicted_stock_price = ysc.inverse_transform(predicted_stock_price)\n",
    "\n",
    "  print(\"Predicted stock price inverse transformed:\",predicted_stock_price[-1])\n",
    "\n",
    "  #The below data's stock price needs to be compared with prediction for the last row from above print\n",
    "  print(\"Previous day data:\",tik_data.iloc[-2,:])\n",
    "  print(\"Check Adj Close for comparison with the inverse transformed predicted stock price\")\n",
    "  #print(\"Actual stock price:\",tik_data.iloc[-1,:])\n",
    "  \n",
    "  \n",
    "  #Calculating the top mover category using above predictions\n",
    "  percent_change = ((predicted_stock_price[-1]-tik_data.iloc[-2,4])/tik_data.iloc[-2,4])*100\n",
    "  print(\"Percentage change expected next day\",percent_change)\n",
    "  if percent_change > int(defined_topmover_threshold) and percent_change > 0: \n",
    "    print(tik,\"stock is predicted to be a top mover the next day\")\n",
    "  else: print(tik,\"stock might not be a top mover the next day\")\n",
    "  print(\"##############################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pbKlAyvmX_w"
   },
   "source": [
    "# LSTM PREDICTIONS USING SENTIMENT SCORE INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "p9kLte0XYXlu"
   },
   "outputs": [],
   "source": [
    "def create_model(units,optimizer,dropout_rate):\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.LSTM(units = units, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    # Compile model\n",
    "    #optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHN9Z_GaKL5o",
    "outputId": "064dff31-cd8d-4d66-f950-63db603b16a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.1min\n",
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 19.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.000720 using {'batch_size': 7, 'dropout_rate': 0.1, 'epochs': 50, 'optimizer': 'SGD', 'units': 1}\n",
      "##############################################################################\n",
      "MSE for SOHU stock using Sentiment scores: 0.8923661708831787\n",
      "Predicted stock price inverse transformed: [56.52957]\n",
      "Previous day data: Open             36.430000\n",
      "High             36.980000\n",
      "Low              36.130001\n",
      "Close            36.590000\n",
      "Adj Close        36.590000\n",
      "Volume       149100.000000\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [54.49459]\n",
      "SOHU stock is predicted to be a top mover the next day going above defined threshold 20 %\n",
      "##############################################################################\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 19.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.001440 using {'batch_size': 7, 'dropout_rate': 0.1, 'epochs': 50, 'optimizer': 'SGD', 'units': 1}\n",
      "##############################################################################\n",
      "MSE for NKTR stock using Sentiment scores: 1.4331543445587158\n",
      "Predicted stock price inverse transformed: [10.216975]\n",
      "Previous day data: Open              13.58\n",
      "High              13.93\n",
      "Low               13.54\n",
      "Close             13.76\n",
      "Adj Close         13.76\n",
      "Volume       1069700.00\n",
      "Name: 2016-06-28, dtype: float64\n",
      "Check Adj Close for comparison with the inverse transformed predicted stock price\n",
      "Percentage change expected next day [-25.748726]\n",
      "NKTR stock might not be a top mover the next day\n",
      "##############################################################################\n",
      "NKTR stock is predicted to perform worse the next day and could go below the threshold -ve  20 %\n"
     ]
    }
   ],
   "source": [
    "##ZION,KGC,AMD,SOHU,BLIN,WMT,AMGN,NKTR,T,AAPL\n",
    "\n",
    "for tik in ticker_list:\n",
    "  tik_data=pd.read_csv(tik+'.csv',index_col=0)\n",
    "  temp_data=tik_data.drop(['Close'],axis=1)\n",
    "  \n",
    "  with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "  #Scaling the variables(x) and variable(y)\n",
    "  sca = temp_data.iloc[:,:]\n",
    "  #Standardization of data is required as the dataset consists of variables of different scales\n",
    "  sc = StandardScaler()\n",
    "  ysc = StandardScaler()\n",
    "  scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "  scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "  \n",
    "  #Y scaling for later inverse transforming predictions\n",
    "  yscalesenti = with_sentiment_data\n",
    "  y_with_sentiscal = ysc.fit_transform(yscalesenti.iloc[:,4].to_numpy().reshape(-1,1))\n",
    "  with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "\n",
    "  with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "  x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "  y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "  \n",
    "  x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "  y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "  #Splitting data into training(70% data) and testing data(30% data)\n",
    "  #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "  \n",
    "  x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "  x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "  TIME_STEPS = 1\n",
    "\n",
    "  #creating lags for with sentiment scores\n",
    "  \n",
    "  x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "  x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "  \n",
    "  #creating lags for without sentiment scores\n",
    "  \n",
    "  x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "  x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "  \n",
    "  x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "  x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "  \n",
    "  x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "  x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "  \n",
    "  np.random.seed = 1   \n",
    "  tf.random.set_seed = 2  \n",
    "  time3=fun_t()\n",
    "  \n",
    "  ########################HYPERPARAMETER TUNING################################################################################\n",
    "  lstm_model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "  param_grid = dict(units = [1,2],optimizer=['SGD', 'Adam'],dropout_rate=[0.1,0.2],batch_size = [7,28],epochs = [50,100,150])\n",
    "  grid = GridSearchCV(estimator=lstm_model, param_grid=param_grid, n_jobs=-1, cv=3,verbose=1)\n",
    "  grid_result = grid.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores)\n",
    "\n",
    "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "  params=grid_result.best_params_\n",
    "  \n",
    "  ##################################Tuned Paramters############################################################################\n",
    "  dropout_rate=params.get('dropout_rate')\n",
    "  batch_size=params.get('batch_size')\n",
    "  epoch=params.get('epochs')\n",
    "  opti = params.get('optimizer')\n",
    "  lstm_units=params.get('units')\n",
    "  \n",
    "  ######################################FINAL MODEL FOR MSE CALCULATION###########################################################################\n",
    "  history=History()\n",
    "  lstm_model = Sequential()\n",
    "  lstm_model.add(keras.layers.LSTM(units = lstm_units, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "  lstm_model.add(Dropout(dropout_rate))\n",
    "  lstm_model.add(keras.layers.Dense(units = 1,activation='relu'))\n",
    "  lstm_model.compile(loss='mean_squared_error', optimizer=opti)\n",
    "  history = lstm_model.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs = epoch, shuffle = False, batch_size = batch_size, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "  time_lstm = list(time3.times)\n",
    "  train_lstm = history.history.get('loss')\n",
    "  val_lstm = history.history.get('val_loss')\n",
    "  mse=val_lstm[-1]\n",
    "\n",
    "  print(\"##############################################################################\")\n",
    "  print('MSE for',tik,'stock using Sentiment scores:',mse)\n",
    "\n",
    "  predicted_stock_price=lstm_model.predict(x_test_with_sentiment_scores)\n",
    "  predicted_stock_price = ysc.inverse_transform(predicted_stock_price)\n",
    "  \n",
    "  print(\"Predicted stock price inverse transformed:\",predicted_stock_price[-1])\n",
    "  \n",
    "  #The below data's stock price needs to be compared with prediction for the last row from above print\n",
    "  print(\"Previous day data:\",tik_data.iloc[-2,:])\n",
    "  #print(\"Actual stock price:\",tik_data.iloc[-1,:])\n",
    "  print(\"Check Adj Close for comparison with the inverse transformed predicted stock price\")\n",
    "  #Calculating the top mover category using above predictions\n",
    "  percent_change = ((predicted_stock_price[-1]-tik_data.iloc[-2,4])/tik_data.iloc[-2,4])*100\n",
    "  print(\"Percentage change expected next day\",percent_change)\n",
    "  if percent_change > int(defined_topmover_threshold) and percent_change > 0: \n",
    "    print(tik,\"stock is predicted to be a top mover the next day going above defined threshold\",defined_topmover_threshold,\"%\")\n",
    "  else: print(tik,\"stock might not be a top mover the next day\")\n",
    "  print(\"##############################################################################\")\n",
    "  if percent_change < abs(int(defined_topmover_threshold)) and percent_change < 0: \n",
    "    print(tik,\"stock is predicted to perform worse the next day and could go below the threshold -ve \",defined_topmover_threshold,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MGOVcITXthX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prediction_TopMover_FinalCode.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
